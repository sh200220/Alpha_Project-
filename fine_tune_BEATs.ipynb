{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbqWTdT9xtFk",
        "outputId": "785ea83d-5d82-4113-9561-a89529549a83"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlvnjXW1vTxS",
        "outputId": "f57769ab-e5a7-417f-fb17-1fda1779da78"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/unilm/beats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npN9OckTAOGl"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJhzaoxT_ww3",
        "outputId": "a17a21d1-a420-435f-c931-93c4a5c3b967"
      },
      "outputs": [],
      "source": [
        "!pip install audiomentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxiWItjpuXKG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Gain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from BEATs import BEATs, BEATsConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "5t5ZlytJ-zLf",
        "outputId": "7d4cac89-31b3-4300-fdda-addd82174a2b"
      },
      "outputs": [],
      "source": [
        "# 증강 파이프라인 설정\n",
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n",
        "    Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.5),\n",
        "])\n",
        "\n",
        "# 오디오 증강 함수\n",
        "def augment_audio(audio, sr):\n",
        "    return augment(samples=audio, sample_rate=sr)\n",
        "\n",
        "# 폴더 경로 설정\n",
        "normal_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/alpha_AIhub_data/3.차량주행음\"\n",
        "abnormal_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/alpha_beats_eval_data\"\n",
        "train_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/train\"\n",
        "test_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/test\"\n",
        "\n",
        "# 폴더 생성\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Normal 및 Abnormal 파일 수집\n",
        "normal_files = [os.path.join(normal_folder, f) for f in os.listdir(normal_folder) if f.endswith('.wav')]\n",
        "abnormal_files = [os.path.join(abnormal_folder, f) for f in os.listdir(abnormal_folder) if f.endswith('.wav')]\n",
        "\n",
        "# Train/Test Split\n",
        "normal_train, normal_test = train_test_split(normal_files, test_size=0.2, random_state=42)\n",
        "abnormal_train, abnormal_test = train_test_split(abnormal_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# 원본 데이터 파일 이동\n",
        "for f in normal_train + abnormal_train:\n",
        "    shutil.copy(f, os.path.join(train_folder, os.path.basename(f)))\n",
        "\n",
        "for f in normal_test + abnormal_test:\n",
        "    shutil.copy(f, os.path.join(test_folder, os.path.basename(f)))\n",
        "\n",
        "# 오디오 증강 및 저장\n",
        "sr = 16000  # 샘플링 레이트\n",
        "augmented_files = []\n",
        "augmented_labels = []\n",
        "for f in normal_train + abnormal_train:\n",
        "    audio, _ = librosa.load(f, sr=sr)\n",
        "    for i in range(3):  # 각 파일당 3개의 증강 데이터 생성\n",
        "        augmented_audio = augment_audio(audio, sr)\n",
        "        augmented_filename = f\"aug_{os.path.basename(f).split('.')[0]}_{i}.wav\"\n",
        "        augmented_filepath = os.path.join(train_folder, augmented_filename)\n",
        "        sf.write(augmented_filepath, augmented_audio, sr)  # soundfile로 파일 저장\n",
        "        augmented_files.append(augmented_filename)\n",
        "        augmented_labels.append(0 if f in normal_train else 1)\n",
        "\n",
        "# 라벨 추가\n",
        "train_labels = [0] * len(normal_train) + [1] * len(abnormal_train) + augmented_labels\n",
        "test_labels = [0] * len(normal_test) + [1] * len(abnormal_test)\n",
        "\n",
        "train_files = [os.path.basename(f) for f in normal_train + abnormal_train] + augmented_files\n",
        "test_files = [os.path.basename(f) for f in normal_test + abnormal_test]\n",
        "\n",
        "# DataFrame 생성\n",
        "train_df = pd.DataFrame({\"filename\": train_files, \"label\": train_labels})\n",
        "test_df = pd.DataFrame({\"filename\": test_files, \"label\": test_labels})\n",
        "\n",
        "# CSV 저장\n",
        "train_csv_path = \"/content/drive/MyDrive/unilm/beats/alpha_data/train_data.csv\"\n",
        "test_csv_path = \"/content/drive/MyDrive/unilm/beats/alpha_data/test_data.csv\"\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"Train files: {len(train_files)}\")\n",
        "print(f\"Test files: {len(test_files)}\")\n",
        "print(f\"Train CSV saved at: {train_csv_path}\")\n",
        "print(f\"Test CSV saved at: {test_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZwaCrChlOiq",
        "outputId": "44ad2cda-f3e3-4ca3-d82f-b8d1b8fa1ebc"
      },
      "outputs": [],
      "source": [
        "# Dataset 정의\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, csv_path, audio_folder):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.audio_folder = audio_folder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        filepath = os.path.join(self.audio_folder, row['filename'])\n",
        "        label = torch.tensor(row['label'], dtype=torch.float32)\n",
        "\n",
        "        # 오디오 로드\n",
        "        audio, _ = librosa.load(filepath, sr=16000)\n",
        "        audio = torch.tensor(audio, dtype=torch.float32)\n",
        "\n",
        "        return audio, label\n",
        "\n",
        "# Collate Function 정의 (패딩 처리)\n",
        "def pad_collate_fn(batch):\n",
        "    inputs, labels = zip(*batch)\n",
        "    max_len = max(input.size(0) for input in inputs)\n",
        "    inputs = [F.pad(input, (0, max_len - input.size(0))) for input in inputs]\n",
        "    inputs = torch.stack(inputs, dim=0)\n",
        "    labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    return inputs, labels\n",
        "\n",
        "# Train/Test DataLoader 준비\n",
        "train_csv = \"/content/drive/MyDrive/unilm/beats/alpha_data/train_data.csv\"\n",
        "test_csv = \"/content/drive/MyDrive/unilm/beats/alpha_data/test_data.csv\"\n",
        "\n",
        "train_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/train\"\n",
        "test_folder = \"/content/drive/MyDrive/unilm/beats/alpha_data/test\"\n",
        "\n",
        "train_dataset = AudioDataset(csv_path=train_csv, audio_folder=train_folder)\n",
        "test_dataset = AudioDataset(csv_path=test_csv, audio_folder=test_folder)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate_fn)\n",
        "\n",
        "print(f\"Train set size: {len(train_loader)}\")\n",
        "print(f\"Test set size: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CpKTtm3fXJq"
      },
      "source": [
        "### 기존 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89pJ76JDlr7d",
        "outputId": "31a6b9d1-4c90-4f02-be44-563a938d2bce"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# AUC 및 PAUC 계산 함수\n",
        "def calculate_auc_pauc(test_loader, model, pauc_fpr_range=(0.0, 0.1)):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 모델에서 예측 확률과 실제 라벨 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            # BEATs 모델에서 특징 추출\n",
        "            features, _ = model.extract_features(inputs, skip_predictor=True)\n",
        "            features = features.mean(dim=1)  # 시간축 평균\n",
        "            probs = torch.sigmoid(features[:, 0])  # 첫 번째 차원을 확률로 사용\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # NumPy 배열로 변환\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # 두 클래스가 포함되었는지 확인\n",
        "    if len(np.unique(all_labels)) < 2:\n",
        "        raise ValueError(\"Test set contains only one class. AUC/PAUC cannot be calculated.\")\n",
        "\n",
        "    # AUC 계산\n",
        "    auc_value = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # PAUC 계산 (FPR 0.0–0.1 구간)\n",
        "    pauc_value = roc_auc_score(all_labels, all_probs, max_fpr=pauc_fpr_range[1])\n",
        "\n",
        "    print(f\"AUC (overall 0.0-1.0): {auc_value:.4f}\")\n",
        "    print(f\"PAUC (FPR {pauc_fpr_range[0]}-{pauc_fpr_range[1]}): {pauc_value:.4f}\")\n",
        "\n",
        "    return auc_value, pauc_value\n",
        "\n",
        "# 평가 실행\n",
        "auc, pauc = calculate_auc_pauc(test_loader, base_model, pauc_fpr_range=(0.0, 0.1))\n",
        "\n",
        "print(f\"Final AUC: {auc:.4f}\")\n",
        "print(f\"Final PAUC: {pauc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tODN7_AmpJUn"
      },
      "source": [
        "### weight loss 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbIqPk1NpNjm",
        "outputId": "aeb45dc8-3623-46bc-c337-360f56838722"
      },
      "outputs": [],
      "source": [
        "# BEATs 기반 이진 분류기 정의 (Dropout 추가)\n",
        "class BEATsBinaryClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(BEATsBinaryClassifier, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(0.1)  # 드롭아웃 확률 설정\n",
        "        self.fc = nn.Linear(768, 1)  # BEATs 출력 크기: 768 -> 이진 분류 (1개 출력)\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        with torch.no_grad():  # Feature extractor 고정\n",
        "            features, _ = self.base_model.extract_features(x, padding_mask=padding_mask, skip_predictor=True)\n",
        "        features = features.mean(dim=1)  # 시간 축 평균\n",
        "        features = self.dropout(features)  # 드롭아웃 적용\n",
        "        logits = self.fc(features)  # 이진 분류 로짓 출력\n",
        "        return logits\n",
        "\n",
        "# BEATs 모델 로드\n",
        "checkpoint_path = '/content/drive/MyDrive/unilm/beats/BEATs_iter3.pt'\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "cfg = BEATsConfig({**checkpoint['cfg'], \"finetuned_model\": True})  # BEATs 설정\n",
        "base_model = BEATs(cfg)\n",
        "base_model.load_state_dict(checkpoint['model'], strict=False)\n",
        "base_model.eval()\n",
        "\n",
        "# 이진 분류 모델 초기화\n",
        "binary_model = BEATsBinaryClassifier(base_model).to(\"cuda\")\n",
        "\n",
        "# 클래스별 가중치 계산\n",
        "from collections import Counter\n",
        "\n",
        "# AudioDataset 객체에서 라벨 추출\n",
        "labels = [int(sample[1].item()) for sample in train_dataset]  # train_dataset의 모든 샘플에서 라벨만 추출\n",
        "label_counts = Counter(labels)  # 라벨 분포 계산\n",
        "\n",
        "# 가중치 계산\n",
        "total_count = sum(label_counts.values())\n",
        "class_weights = torch.tensor([total_count / label_counts[0], total_count / label_counts[1]], dtype=torch.float32).to(\"cuda\")\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Weighted BCEWithLogitsLoss 설정\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])  # 양성 클래스에 대한 가중치 적용\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.Adam(binary_model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "early_stopping_patience = 5  # Early Stopping 기준 에포크 수\n",
        "no_improvement_count = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    binary_model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = binary_model(inputs)  # 모델 출력\n",
        "        loss = criterion(logits.view(-1), labels)  # 손실 계산 (가중치 적용)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    binary_model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = binary_model(inputs)\n",
        "            probs = torch.sigmoid(logits.view(-1))\n",
        "            preds = (probs > 0.3).float()\n",
        "            loss = criterion(logits.view(-1), labels)\n",
        "            val_loss += loss.item()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping 검증 및 최적 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improvement_count = 0  # 개선되었으므로 초기화\n",
        "        # 최적 모델 저장\n",
        "        torch.save({\n",
        "            'model_state_dict': binary_model.state_dict(),  # 이진 분류 모델의 상태 저장\n",
        "            'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장\n",
        "            'epoch': epoch,  # 현재 에포크\n",
        "            'best_val_loss': best_val_loss  # 최적 Validation Loss\n",
        "        }, \"/content/drive/MyDrive/PretrainedSED/sigmoid_binary_best.pt\")  # 저장 경로\n",
        "        print(f\"Model saved with Validation Loss: {best_val_loss:.4f}\")\n",
        "    else:\n",
        "        no_improvement_count += 1  # 개선되지 않으면 증가\n",
        "        print(f\"No improvement in Validation Loss for {no_improvement_count} epochs.\")\n",
        "\n",
        "    # Early Stopping 조건\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "# 학습 완료 후 저장된 모델로 AUC/PAUC 평가 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "rV5xCHVspNmI",
        "outputId": "c85633c4-5bac-4323-c0b8-0268f3960028"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# AUC 및 PAUC 계산 함수\n",
        "def calculate_auc_pauc(test_loader, model, pauc_fpr_range=(0.0, 0.1)):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 모델에서 예측 확률과 실제 라벨 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = model(inputs)\n",
        "            probs = torch.sigmoid(logits.squeeze())  # 확률 계산\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # NumPy 배열로 변환\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # AUC 계산\n",
        "    auc_value = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # PAUC 계산 (FPR 0.0–0.1 구간)\n",
        "    pauc_value = roc_auc_score(all_labels, all_probs, max_fpr=pauc_fpr_range[1])\n",
        "\n",
        "    print(f\"AUC (overall 0.0-1.0): {auc_value:.4f}\")\n",
        "    print(f\"PAUC (FPR {pauc_fpr_range[0]}-{pauc_fpr_range[1]}): {pauc_value:.4f}\")\n",
        "\n",
        "    return auc_value, pauc_value\n",
        "\n",
        "# 평가 실행\n",
        "auc, pauc = calculate_auc_pauc(test_loader, binary_model, pauc_fpr_range=(0.0, 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrPJvWOknWW-"
      },
      "source": [
        "### hard negative 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNAvlPTfnZOL",
        "outputId": "b226034b-1eb6-46b7-899e-2161db4ab12b"
      },
      "outputs": [],
      "source": [
        "# BEATs 기반 이진 분류기 정의 (Dropout 추가)\n",
        "class BEATsBinaryClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(BEATsBinaryClassifier, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(0.1)  # 드롭아웃 확률 설정\n",
        "        self.fc = nn.Linear(768, 1)  # BEATs 출력 크기: 768 -> 이진 분류 (1개 출력)\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        with torch.no_grad():  # Feature extractor 고정\n",
        "            features, _ = self.base_model.extract_features(x, padding_mask=padding_mask, skip_predictor=True)\n",
        "        features = features.mean(dim=1)  # 시간 축 평균\n",
        "        features = self.dropout(features)  # 드롭아웃 적용\n",
        "        logits = self.fc(features)  # 이진 분류 로짓 출력\n",
        "        return logits\n",
        "\n",
        "# Hard Negative Mining 함수\n",
        "def hard_negative_mining(loader, model, threshold=0.5):\n",
        "    model.eval()\n",
        "    hard_negatives = []\n",
        "    hard_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = model(inputs)\n",
        "            probs = torch.sigmoid(logits.view(-1))\n",
        "            preds = (probs > threshold).float()\n",
        "\n",
        "            # 잘못 예측된 음성 데이터(음성인데 양성으로 분류됨)\n",
        "            incorrect_indices = (preds == 1) & (labels == 0)\n",
        "            for idx in torch.where(incorrect_indices)[0]:\n",
        "                hard_negatives.append(inputs[idx].cpu())\n",
        "                hard_labels.append(labels[idx].cpu())\n",
        "\n",
        "    if len(hard_negatives) > 0:\n",
        "        hard_negatives = torch.stack(hard_negatives)\n",
        "        hard_labels = torch.stack(hard_labels)\n",
        "\n",
        "    return hard_negatives, hard_labels\n",
        "\n",
        "# BEATs 모델 로드\n",
        "checkpoint_path = '/content/drive/MyDrive/unilm/beats/BEATs_iter3.pt'\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "cfg = BEATsConfig({**checkpoint['cfg'], \"finetuned_model\": True})  # BEATs 설정\n",
        "base_model = BEATs(cfg)\n",
        "base_model.load_state_dict(checkpoint['model'], strict=False)\n",
        "base_model.eval()\n",
        "\n",
        "# 이진 분류 모델 초기화\n",
        "binary_model = BEATsBinaryClassifier(base_model).to(\"cuda\")\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.BCEWithLogitsLoss()  # 시그모이드를 위한 손실 함수\n",
        "optimizer = optim.Adam(binary_model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 10\n",
        "early_stopping_patience = 5  # Early Stopping 기준 에포크 수\n",
        "no_improvement_count = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    binary_model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = binary_model(inputs)  # 모델 출력\n",
        "        loss = criterion(logits.view(-1), labels)  # 손실 계산\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Hard Negative Mining 실행\n",
        "    hard_negatives, hard_labels = hard_negative_mining(train_loader, binary_model, threshold=0.5)\n",
        "    if len(hard_negatives) > 0:\n",
        "        print(f\"Found {len(hard_negatives)} hard negative samples. Adding them to training.\")\n",
        "        # Hard Negative 샘플을 DataLoader에 추가\n",
        "        hard_negatives = hard_negatives.to(\"cuda\")\n",
        "        hard_labels = hard_labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        logits = binary_model(hard_negatives)\n",
        "        loss = criterion(logits.view(-1), hard_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    binary_model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = binary_model(inputs)\n",
        "            probs = torch.sigmoid(logits.view(-1))\n",
        "            preds = (probs > 0.3).float()\n",
        "            loss = criterion(logits.view(-1), labels)\n",
        "            val_loss += loss.item()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping 검증 및 최적 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improvement_count = 0  # 개선되었으므로 초기화\n",
        "        # 최적 모델 저장\n",
        "        torch.save({\n",
        "            'model_state_dict': binary_model.state_dict(),  # 이진 분류 모델의 상태 저장\n",
        "            'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장\n",
        "            'epoch': epoch,  # 현재 에포크\n",
        "            'best_val_loss': best_val_loss  # 최적 Validation Loss\n",
        "        }, \"/content/drive/MyDrive/PretrainedSED/sigmoid_binary_best.pt\")  # 저장 경로\n",
        "        print(f\"Model saved with Validation Loss: {best_val_loss:.4f}\")\n",
        "    else:\n",
        "        no_improvement_count += 1  # 개선되지 않으면 증가\n",
        "        print(f\"No improvement in Validation Loss for {no_improvement_count} epochs.\")\n",
        "\n",
        "    # Early Stopping 조건\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "# 학습 완료 후 저장된 모델로 AUC/PAUC 평가 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4-hSTbACqr6",
        "outputId": "d0941e43-d357-4222-cfd6-9ef9496b528d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# AUC 및 PAUC 계산 함수\n",
        "def calculate_auc_pauc(test_loader, model, pauc_fpr_range=(0.0, 0.1)):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 모델에서 예측 확률과 실제 라벨 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = model(inputs)\n",
        "            probs = torch.sigmoid(logits.squeeze())  # 확률 계산\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # NumPy 배열로 변환\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # AUC 계산\n",
        "    auc_value = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # PAUC 계산 (FPR 0.0–0.1 구간)\n",
        "    pauc_value = roc_auc_score(all_labels, all_probs, max_fpr=pauc_fpr_range[1])\n",
        "\n",
        "    print(f\"AUC (overall 0.0-1.0): {auc_value:.4f}\")\n",
        "    print(f\"PAUC (FPR {pauc_fpr_range[0]}-{pauc_fpr_range[1]}): {pauc_value:.4f}\")\n",
        "\n",
        "    return auc_value, pauc_value\n",
        "\n",
        "# 평가 실행\n",
        "auc, pauc = calculate_auc_pauc(test_loader, binary_model, pauc_fpr_range=(0.0, 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rofe08pcetuK"
      },
      "source": [
        "### hard+weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "3eKQkxCWexZF",
        "outputId": "550924f9-7888-4108-b5f7-27fd775db8b1"
      },
      "outputs": [],
      "source": [
        "# BEATs 기반 이진 분류기 정의 (Dropout 추가)\n",
        "class BEATsBinaryClassifier(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(BEATsBinaryClassifier, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(0.1)  # 드롭아웃 확률 설정\n",
        "        self.fc = nn.Linear(768, 1)  # BEATs 출력 크기: 768 -> 이진 분류 (1개 출력)\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        with torch.no_grad():  # Feature extractor 고정\n",
        "            features, _ = self.base_model.extract_features(x, padding_mask=padding_mask, skip_predictor=True)\n",
        "        features = features.mean(dim=1)  # 시간 축 평균\n",
        "        features = self.dropout(features)  # 드롭아웃 적용\n",
        "        logits = self.fc(features)  # 이진 분류 로짓 출력\n",
        "        return logits\n",
        "\n",
        "# Hard Negative Mining 함수 (패딩 추가)\n",
        "def hard_negative_mining(loader, model, threshold=0.5):\n",
        "    model.eval()\n",
        "    hard_negatives = []\n",
        "    hard_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = model(inputs)\n",
        "            probs = torch.sigmoid(logits.view(-1))\n",
        "            preds = (probs > threshold).float()\n",
        "\n",
        "            # 잘못 예측된 음성 데이터(음성인데 양성으로 분류됨)\n",
        "            incorrect_indices = (preds == 1) & (labels == 0)\n",
        "            for idx in torch.where(incorrect_indices)[0]:\n",
        "                hard_negatives.append(inputs[idx].cpu())\n",
        "                hard_labels.append(labels[idx].cpu())\n",
        "\n",
        "    if len(hard_negatives) > 0:\n",
        "        # 텐서 크기 통일 (패딩 처리)\n",
        "        max_len = max(neg.size(0) for neg in hard_negatives)  # 가장 긴 데이터 길이 확인\n",
        "        hard_negatives = [F.pad(neg, (0, max_len - neg.size(0))) for neg in hard_negatives]\n",
        "        hard_negatives = torch.stack(hard_negatives)  # 스택으로 변환\n",
        "        hard_labels = torch.tensor(hard_labels, dtype=torch.float32)  # 라벨 변환\n",
        "\n",
        "    return hard_negatives, hard_labels\n",
        "\n",
        "# BEATs 모델 로드\n",
        "checkpoint_path = '/content/drive/MyDrive/unilm/beats/BEATs_iter3.pt'\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "cfg = BEATsConfig({**checkpoint['cfg'], \"finetuned_model\": True})  # BEATs 설정\n",
        "base_model = BEATs(cfg)\n",
        "base_model.load_state_dict(checkpoint['model'], strict=False)\n",
        "base_model.eval()\n",
        "\n",
        "# 이진 분류 모델 초기화\n",
        "binary_model = BEATsBinaryClassifier(base_model).to(\"cuda\")\n",
        "\n",
        "# 클래스별 가중치 계산\n",
        "from collections import Counter\n",
        "\n",
        "labels = [label.item() for _, label in train_loader.dataset]  # 전체 학습 데이터 라벨 추출\n",
        "label_counts = Counter(labels)\n",
        "total_count = sum(label_counts.values())\n",
        "class_weights = torch.tensor([total_count / label_counts[0], total_count / label_counts[1]], dtype=torch.float32).to(\"cuda\")\n",
        "\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "# Weighted BCEWithLogitsLoss 설정\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])  # 양성 클래스 가중치 적용\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.Adam(binary_model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 5\n",
        "early_stopping_patience = 5  # Early Stopping 기준 에포크 수\n",
        "no_improvement_count = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    binary_model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Train 데이터 학습\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = binary_model(inputs)\n",
        "        loss = criterion(logits.view(-1), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Hard Negative Mining 실행\n",
        "    hard_negatives, hard_labels = hard_negative_mining(train_loader, binary_model, threshold=0.5)\n",
        "    if len(hard_negatives) > 0:\n",
        "        # 위의 수정된 배치 처리 + Mixed Precision Training 코드 삽입\n",
        "        scaler = torch.cuda.amp.GradScaler()\n",
        "        batch_size = 16\n",
        "        for i in range(0, len(hard_negatives), batch_size):\n",
        "            batch_negatives = hard_negatives[i:i + batch_size].to(\"cuda\")\n",
        "            batch_labels = hard_labels[i:i + batch_size].to(\"cuda\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = binary_model(batch_negatives)\n",
        "                loss = criterion(logits.view(-1), batch_labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    # Validation\n",
        "    binary_model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = binary_model(inputs)\n",
        "            probs = torch.sigmoid(logits.view(-1))\n",
        "            preds = (probs > 0.5).float()\n",
        "            loss = criterion(logits.view(-1), labels)\n",
        "            val_loss += loss.item()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping 검증 및 최적 모델 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improvement_count = 0  # 개선되었으므로 초기화\n",
        "        # 최적 모델 저장\n",
        "        torch.save({\n",
        "            'model_state_dict': binary_model.state_dict(),  # 이진 분류 모델의 상태 저장\n",
        "            'optimizer_state_dict': optimizer.state_dict(),  # 옵티마이저 상태 저장\n",
        "            'epoch': epoch,  # 현재 에포크\n",
        "            'best_val_loss': best_val_loss  # 최적 Validation Loss\n",
        "        }, \"/content/drive/MyDrive/PretrainedSED/sigmoid_binary_best.pt\")  # 저장 경로\n",
        "        print(f\"Model saved with Validation Loss: {best_val_loss:.4f}\")\n",
        "    else:\n",
        "        no_improvement_count += 1  # 개선되지 않으면 증가\n",
        "        print(f\"No improvement in Validation Loss for {no_improvement_count} epochs.\")\n",
        "\n",
        "    # Early Stopping 조건\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "        break\n",
        "\n",
        "# 학습 완료 후 저장된 모델로 AUC/PAUC 평가 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wt8fqTgexcc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# AUC 및 PAUC 계산 함수\n",
        "def calculate_auc_pauc(test_loader, model, pauc_fpr_range=(0.0, 0.1)):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 모델에서 예측 확률과 실제 라벨 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            logits = model(inputs)\n",
        "            probs = torch.sigmoid(logits.squeeze())  # 확률 계산\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # NumPy 배열로 변환\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # AUC 계산\n",
        "    auc_value = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    # PAUC 계산 (FPR 0.0–0.1 구간)\n",
        "    pauc_value = roc_auc_score(all_labels, all_probs, max_fpr=pauc_fpr_range[1])\n",
        "\n",
        "    print(f\"AUC (overall 0.0-1.0): {auc_value:.4f}\")\n",
        "    print(f\"PAUC (FPR {pauc_fpr_range[0]}-{pauc_fpr_range[1]}): {pauc_value:.4f}\")\n",
        "\n",
        "    return auc_value, pauc_value\n",
        "\n",
        "# 평가 실행\n",
        "auc, pauc = calculate_auc_pauc(test_loader, binary_model, pauc_fpr_range=(0.0, 0.1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
